# Configuración de entorno para agentes IA
# Copia este archivo a .env y configura las variables

# =============================================================================
# CONFIGURACIÓN LOCAL (PRINCIPAL - RECOMENDADO PARA DESARROLLO)
# =============================================================================

# Ollama configuración - Proveedor principal por defecto para desarrollo local
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama2

# =============================================================================
# CONFIGURACIÓN REMOTA (FALLBACK - SOLO PARA SOBRECARGA/EMERGENCIAS)
# =============================================================================
# Estos proveedores se usan automáticamente solo si Ollama falla o está sobrecargado

# GitHub Models (Fallback 1)
GITHUB_TOKEN=your_github_token_here

# Azure AI Foundry (Fallback 2)
AZURE_OPENAI_API_KEY=your_azure_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=your_deployment_name

# OpenAI (Opcional - no configurado en fallback por defecto)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (Opcional - no configurado en fallback por defecto)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# =============================================================================
# CONFIGURACIÓN GENERAL
# =============================================================================

# Configuración de logging
LOG_LEVEL=INFO
LOG_FILE=logs/agents.log

# Configuración de base de datos (si aplica)
DATABASE_URL=sqlite:///agents.db

# Configuración de seguridad
SECRET_KEY=your_secret_key_here